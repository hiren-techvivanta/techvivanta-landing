# robots.txt for https://www.techvivanta.com/

User-agent: *
Allow: /
Disallow: /admin/
Disallow: /cgi-bin/
Disallow: /temp/
Disallow: /private/

# Crawl delay (optional â€“ helps prevent server overload)
Crawl-delay: 10

# Sitemap location
Sitemap: https://www.techvivanta.com/sitemap.xml

# Additional notes
# This file tells search engines what they can and cannot crawl.
# You can safely modify the Disallow paths if you add new private sections.
